{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "oPGLBeegScnA"
   },
   "source": [
    "# Train a deep CNN on XPS data on local machine"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "UnizRikuXSq_"
   },
   "source": [
    "In this notebook, we will train a deep convolutional network on iron XPS spectra using the local CPU/GPU."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "1JaT35fVScnE"
   },
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "T4udSXQx9xGb"
   },
   "source": [
    "### Install packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "y0asYF8EScnE"
   },
   "outputs": [],
   "source": [
    "# Imports\n",
    "import os\n",
    "import datetime\n",
    "import pytz\n",
    "import numpy as np\n",
    "import importlib\n",
    "\n",
    "# Magic commands\n",
    "%matplotlib inline\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"all\"\n",
    "\n",
    "# Run tensorflow on local CPU\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"] = \"PCI_BUS_ID\"\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"-1\"\n",
    "\n",
    "# Disable tf warnings\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'\n",
    "\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Sie7aI1R9xGe"
   },
   "source": [
    "### Load custom modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "zz-HVIuTSgp7",
    "outputId": "ff0ec6ad-490b-4252-e739-b5eeba64c8a1"
   },
   "outputs": [],
   "source": [
    "try:\n",
    "    import importlib\n",
    "    importlib.reload(classifier)\n",
    "    importlib.reload(clfutils)\n",
    "    print('Modules were reloaded.')\n",
    "except:\n",
    "    import network.classifier as classifier\n",
    "    import network.utils as clfutils\n",
    "    print('Modules were loaded.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "akcfhdYVScnH"
   },
   "source": [
    "## Initial run"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "gFhZvpTIScnH"
   },
   "source": [
    "### Setting up the parameters & folder structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "gUcC7b9YScnI",
    "outputId": "d8a4d299-937c-4772-a38d-58b96c78c8c8"
   },
   "outputs": [],
   "source": [
    "np.random.seed(502)\n",
    "time =  datetime.datetime.now().astimezone(pytz.timezone('Europe/Berlin')).strftime(\"%Y%m%d_%Hh%Mm\")\n",
    "data_name = 'Fe_multiple_4_classes'\n",
    "\n",
    "label_values = ['Fe metal', 'FeO', 'Fe3O4', 'Fe2O3']\n",
    "\n",
    "clf = classifier.ClassifierMultiple(time = time,\n",
    "                                    data_name = data_name,\n",
    "                                    labels = label_values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "wi-TLcucScnK"
   },
   "source": [
    "### Load and inspect the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "CRMFaHzEScnK",
    "outputId": "0597be2e-d42d-4eca-a72c-823ebbcadae6"
   },
   "outputs": [],
   "source": [
    "input_filepath = r'C:\\Users\\pielsticker\\Simulations\\20200622_iron_linear_combination_1000000.h5'   \n",
    "train_test_split = 0.2\n",
    "train_val_split = 0.2\n",
    "no_of_examples = 1000\n",
    "\n",
    "X_train, X_val, X_test, y_train, y_val, y_test = clf.load_data_preprocess(input_filepath = input_filepath,\n",
    "                                                                          no_of_examples = no_of_examples,\n",
    "                                                                          train_test_split = train_test_split,\n",
    "                                                                          train_val_split = train_val_split)\n",
    "# Check how the examples are distributed across the classes:\n",
    "class_distribution = clf.check_class_distribution()\n",
    "clf.plot_class_distribution()\n",
    "clf.plot_random(no_of_spectra = 9, dataset = 'train')  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "kxaSnAeIScnN"
   },
   "source": [
    "### Design the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "IqbvB9zmScnN",
    "outputId": "e9f3f8ea-e5cb-41ab-a4f1-9aae69025ebb"
   },
   "outputs": [],
   "source": [
    "try:\n",
    "    importlib.reload(models)\n",
    "    print('Models module was reloaded.')\n",
    "except:\n",
    "    import network.models as models\n",
    "    print('Models module was loaded.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "FvrQZrXp9xGx"
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, Dense, Flatten, concatenate, Lambda\n",
    "from tensorflow.keras.layers import Conv1D\n",
    "from tensorflow.keras.layers import Dropout\n",
    "from tensorflow.keras.layers import AveragePooling1D, MaxPooling1D\n",
    "from tensorflow.keras.layers import LayerNormalization\n",
    "from tensorflow.python.keras import backend as K\n",
    "\n",
    "class CustomCNNMultiple(models.EmptyModel):\n",
    "    def __init__(self, inputshape, num_classes):      \n",
    "        input_1 = Input(shape = inputshape)\n",
    "                \n",
    "        conv_1_short = Conv1D(4, 5, padding = 'same',\n",
    "                            activation = 'relu')(input_1)\n",
    "        conv_1_medium = Conv1D(4, 10, padding = 'same',\n",
    "                             activation = 'relu')(input_1)\n",
    "        conv_1_long = Conv1D(4, 15, padding = 'same',\n",
    "                           activation = 'relu')(input_1)\n",
    "        sublayers = [conv_1_short, conv_1_medium, conv_1_long]\n",
    "        merged_sublayers = concatenate(sublayers)\n",
    "        \n",
    "        conv_2 = Conv1D(4, 5, activation='relu')(merged_sublayers)\n",
    "        average_pool_1 = AveragePooling1D()(conv_2)\n",
    "        \n",
    "        flatten_1 = Flatten()(average_pool_1)\n",
    "        drop_1 = Dropout(0.2)(flatten_1)\n",
    "        dense_1 = Dense(2000, activation = 'relu')(drop_1)\n",
    "        \n",
    "        dense_2 = Dense(num_classes, activation = 'sigmoid')(dense_1)\n",
    "        \n",
    "        output = Lambda(lambda x: x/K.sum(x), name = 'normalization')(dense_2)\n",
    "\n",
    "        no_of_inputs = len(sublayers)\n",
    "\n",
    "        super(CustomCNNMultiple, self).__init__(inputs = input_1,\n",
    "                                                outputs = output,\n",
    "                                                inputshape = inputshape,\n",
    "                                                num_classes = num_classes,\n",
    "                                                no_of_inputs = no_of_inputs,\n",
    "                                                name = 'Custom_CNN_multiple')        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "yMDpECiq9xGz"
   },
   "source": [
    "### Build the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "2b9ck6vU9xG0"
   },
   "outputs": [],
   "source": [
    "clf.model = CustomCNNMultiple(clf.input_shape, clf.num_classes)\n",
    "\n",
    "# Alternative: Build model from available models\n",
    "# clf.model = models.CustomCNNMultiple(clf.input_shape, clf.num_classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "SsIbOK3DScnP"
   },
   "source": [
    "### Compile and summarize the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "BZvEMMwu9xG3",
    "outputId": "3972c71b-ddf6-4ca9-dede-27f0aba674e8"
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.optimizers import Adam\n",
    "learning_rate = 1e-05\n",
    "optimizer = Adam(learning_rate = learning_rate) \n",
    "\n",
    "\n",
    "def custom_loss(y_true, y_pred):\n",
    "    \"\"\"\n",
    "    Custom loss for linear combination of XPS spectra.\n",
    "    \"\"\"\n",
    "    squared_difference = tf.square(tf.subtract(y_true,y_pred))\n",
    "    squared_output = tf.square(y_pred)\n",
    "    \n",
    "    return tf.reduce_sum(tf.multiply(squared_output,squared_difference))\n",
    "\n",
    "\n",
    "#Compile model with custom loss function\n",
    "clf.model.compile(loss = custom_loss, optimizer = optimizer)\n",
    "\n",
    "\n",
    "\n",
    "# Plot summary and save model plot.\n",
    "clf.summary()\n",
    "clf.save_and_print_model_image()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "BJ1D1JtS9xG6"
   },
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "8xgd0t3aScnQ",
    "outputId": "f1207dd1-ec71-4ccd-b2b6-8c750161d201"
   },
   "outputs": [],
   "source": [
    "epochs = 10\n",
    "batch_size = 32\n",
    "\n",
    "hist = clf.train(checkpoint = True,\n",
    "                 early_stopping = False,\n",
    "                 tb_log = True, \n",
    "                 csv_log = True,\n",
    "                 epochs = epochs, \n",
    "                 batch_size = batch_size,\n",
    "                 verbose = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "rwY64s5fScnS"
   },
   "source": [
    "### Graphs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "tilFEM-ZScnT",
    "outputId": "91fe257d-89b9-49f3-c0e4-22aa96ab7b27"
   },
   "outputs": [],
   "source": [
    "dir_name = clf.time + '_' + clf.data_name\n",
    "graph = clfutils.TrainingGraphs(clf.history, dir_name) \n",
    "graph.plot_loss()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "2hzyq_mYScnV"
   },
   "source": [
    "### Evaluation on test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "O24OMUNKScnV",
    "outputId": "753da7c5-135e-49d0-8f72-8f4e3cd7c86a"
   },
   "outputs": [],
   "source": [
    "test_loss = clf.evaluate()\n",
    "print('Test loss: ' + str(test_loss))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "im-5HFvGScnX"
   },
   "source": [
    "### Prediction on test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Uvb314wPScnY",
    "outputId": "4a0bb89a-84fa-4cb7-e24e-fb79fd50d7c8"
   },
   "outputs": [],
   "source": [
    "pred_train, pred_test = clf.predict()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "hLwmQCSaScna"
   },
   "source": [
    "### Show some predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "n8NzxKX8Scna"
   },
   "source": [
    "#### Training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ZeJgwhuDScnb",
    "outputId": "084be023-3c8b-43fe-a2e4-30936ea31782",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "clf.plot_random(no_of_spectra = 6, dataset = 'train', with_prediction = True)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "htoKHrPkScnd"
   },
   "source": [
    "#### Test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "P7i3oUziScnd",
    "outputId": "437ca245-e091-410f-c08f-13f303722c9e"
   },
   "outputs": [],
   "source": [
    "clf.plot_random(no_of_spectra = 6, dataset = 'test', with_prediction = True)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "oIw_jHjdScnf"
   },
   "source": [
    "### Saving data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "0xkBRtbaScng",
    "outputId": "6ec5e7a4-92b1-4358-8965-389c60528818",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "clf.save_model()\n",
    "clf.save_hyperparams()\n",
    "clf.shelve_results(full = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "GDqgN5mCScni"
   },
   "source": [
    "### Report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "dAvxpYfnScni",
    "outputId": "a92b3026-64c6-46e1-c58b-88ad17e1628a"
   },
   "outputs": [],
   "source": [
    "dir_name = clf.time + '_' + clf.data_name\n",
    "rep = clfutils.Report(dir_name)  \n",
    "rep.write()   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Kh3RH0VTScnk"
   },
   "source": [
    "## Continue training "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "5rqLgWMWScnm",
    "outputId": "d61e8dc9-1921-4184-b720-4270cb669e0a",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Reload and train for more epochs\n",
    "# model_path = r'C:\\Users\\pielsticker\\Lukas\\MPI-CEC\\Projects\\xpsdeeplearning\\saved_models\\20200608_17h51m_Fe_single_4_classes_CNN_simple' \n",
    "clf.load_model()\n",
    "clf.model.compile(loss = 'categorical_crossentropy',\n",
    "                  optimizer = optimizer, \n",
    "                  metrics = ['accuracy'])\n",
    "\n",
    "new_learning_rate = 1e-04\n",
    "epochs = 2\n",
    "batch_size = 32\n",
    "hist = clf.train(checkpoint = True,\n",
    "                 early_stopping = False,\n",
    "                 tb_log = True, \n",
    "                 csv_log = True,\n",
    "                 epochs = epochs,\n",
    "                 batch_size = batch_size, \n",
    "                 new_learning_rate = new_learning_rate) # Learning rate can be changed for retraining\n",
    "\n",
    "from tensorflow.keras import backend as K\n",
    "print('New learning rate: ' +\\\n",
    "      str(K.eval(clf.model.optimizer.lr)))\n",
    "\n",
    "dir_name = clf.time + '_' + clf.data_name\n",
    "graphs = clfutils.TrainingGraphs(hist, dir_name)\n",
    "graph.plot_loss()\n",
    "\n",
    "score = clf.evaluate()\n",
    "test_loss = score[0]\n",
    "\n",
    "pred_train, pred_test = clf.predict()\n",
    "clf.plot_random(no_of_spectra = 6, dataset = 'train', with_prediction = True)  \n",
    "clf.plot_random(no_of_spectra = 6, dataset = 'test', with_prediction = True)  \n",
    "\n",
    "clf.save_model()\n",
    "clf.save_hyperparams()\n",
    "clf.shelve_results(full = False)  \n",
    "\n",
    "rep = clfutils.Report(dir_name)  \n",
    "rep.write()  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "gLJQUtKyScnp"
   },
   "source": [
    "### Save output of notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "wXTzMoApScnq",
    "outputId": "df7d1427-8b1e-4a1b-fa31-86a43d09e336"
   },
   "outputs": [],
   "source": [
    "from IPython.display import Javascript, display\n",
    "from nbconvert import HTMLExporter\n",
    "\n",
    "def save_notebook():\n",
    "    display(Javascript(\"IPython.notebook.save_notebook()\"), include=['application/javascript'])\n",
    "\n",
    "def output_HTML(read_file, output_file):\n",
    "    import codecs\n",
    "    import nbformat\n",
    "    exporter = HTMLExporter()\n",
    "    # read_file is '.ipynb', output_file is '.html'\n",
    "    output_notebook = nbformat.read(read_file, as_version=4)\n",
    "    output, resources = exporter.from_notebook_node(output_notebook)\n",
    "    codecs.open(output_file, 'w', encoding='utf-8').write(output)\n",
    "\n",
    "import time\n",
    "\n",
    "save_notebook()\n",
    "time.sleep(3)\n",
    "current_file = 'train_local_mutliple.ipynb'\n",
    "output_file = os.path.join(clf.log_dir,'train_local_mutliple_out.html')\n",
    "output_HTML(current_file, output_file)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "train_local_mutliple.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
