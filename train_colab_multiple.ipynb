{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "vt5hanGL4WpD"
   },
   "source": [
    "# Train a deep CNN on XPS data on Google Colab"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "uTjEnuR-LwEo"
   },
   "source": [
    "In this notebook, we will train a deep convolutional network on iron XPS spectra using the local CPU/GPU."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "u6EVGrGFLwEr"
   },
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "dU2aEkqdLwE_"
   },
   "source": [
    "### Mount google drive, change working directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "5iL11_yXLwFB"
   },
   "outputs": [],
   "source": [
    "# Mount drive\n",
    "from google.colab import drive\n",
    "import os\n",
    "\n",
    "drive.mount('/content/drive')\n",
    "\n",
    "# Change working path\n",
    "os.chdir('/content/drive/My Drive/app')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "rC3yXYXaLwEt"
   },
   "source": [
    "### Install packages and import modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "s4MxYB_b33V9"
   },
   "outputs": [],
   "source": [
    "# Install packages\n",
    "!pip install python-docx\n",
    "\n",
    "# Import standard modules and magic commands\n",
    "import datetime\n",
    "import numpy as np\n",
    "import pytz\n",
    "import importlib\n",
    "\n",
    "# Magic commands\n",
    "%matplotlib inline\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"all\"\n",
    "\n",
    "# Disable tf warnings\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'\n",
    "\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "-qQx0QfuLwFQ"
   },
   "source": [
    "### Load custom modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "SfLJzbL04VZ8"
   },
   "outputs": [],
   "source": [
    "try:\n",
    "    import importlib\n",
    "    importlib.reload(classifier)\n",
    "    importlib.reload(clfutils)\n",
    "    print('Modules were reloaded.')\n",
    "except:\n",
    "    import xpsdeeplearning.network.classifier as classifier\n",
    "    import xpsdeeplearning.network.utils as clfutils\n",
    "    print('Modules were loaded.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "R1BPxWcLLwFp"
   },
   "source": [
    "## Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "00sFUZszLwFq"
   },
   "source": [
    "### Setting up the parameters & folder structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "GXy2WdXYXcXc"
   },
   "outputs": [],
   "source": [
    "np.random.seed(502)\n",
    "time = datetime.datetime.now().astimezone(pytz.timezone('Europe/Berlin')).strftime(\"%Y%m%d_%Hh%Mm\")\n",
    "data_name = 'Fe_single_4_classes'\n",
    "\n",
    "label_values = ['Fe metal', 'FeO', 'Fe3O4', 'Fe2O3']\n",
    "\n",
    "clf = classifier.ClassifierMultiple(time = time,\n",
    "                                    data_name = data_name,\n",
    "                                    labels = label_values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "q0wkRVOuLwFy"
   },
   "source": [
    "### Load and inspect the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "KZIiyOyKtxmf"
   },
   "outputs": [],
   "source": [
    "input_filepath = r'/content/drive/My Drive/app/datasets/20200622_iron_linear_combination_1000000.h5'\n",
    "train_test_split = 0.2\n",
    "train_val_split = 0.2\n",
    "no_of_examples = 100000\n",
    "\n",
    "X_train, X_val, X_test, y_train, y_val, y_test = \\\n",
    "        clf.load_data_preprocess(input_filepath = input_filepath,\n",
    "                                 no_of_examples = no_of_examples,\n",
    "                                 train_test_split = train_test_split,\n",
    "                                 train_val_split = train_val_split)\n",
    "        \n",
    "# Check how the examples are distributed across the classes.\n",
    "class_distribution = clf.check_class_distribution()\n",
    "clf.plot_class_distribution()\n",
    "clf.plot_random(no_of_spectra = 9, dataset = 'train')  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "TKXmi1LMLwF6"
   },
   "source": [
    "### Design the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "pyxJ9_qh5awz"
   },
   "outputs": [],
   "source": [
    "try:\n",
    "    importlib.reload(models)\n",
    "    print('Models module was reloaded.')\n",
    "except:\n",
    "    import xpsdeeplearning.network.models as models\n",
    "    print('Models module was loaded.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "zlav04xq9Xr6"
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, Dense, Flatten, concatenate, Lambda\n",
    "from tensorflow.keras.layers import Conv1D\n",
    "from tensorflow.keras.layers import Dropout\n",
    "from tensorflow.keras.layers import AveragePooling1D, MaxPooling1D\n",
    "from tensorflow.keras.layers import LayerNormalization\n",
    "from tensorflow.python.keras import backend as K\n",
    "\n",
    "class CustomCNNMultiple(models.EmptyModel):\n",
    "    def __init__(self, inputshape, num_classes):      \n",
    "        input_1 = Input(shape = inputshape)\n",
    "                \n",
    "        conv_1_short = Conv1D(4, 5, padding = 'same',\n",
    "                            activation = 'relu')(input_1)\n",
    "        conv_1_medium = Conv1D(4, 10, padding = 'same',\n",
    "                             activation = 'relu')(input_1)\n",
    "        conv_1_long = Conv1D(4, 15, padding = 'same',\n",
    "                           activation = 'relu')(input_1)\n",
    "        sublayers = [conv_1_short, conv_1_medium, conv_1_long]\n",
    "        merged_sublayers = concatenate(sublayers)\n",
    "        \n",
    "        conv_2 = Conv1D(4, 5, activation='relu')(merged_sublayers)\n",
    "        average_pool_1 = AveragePooling1D()(conv_2)\n",
    "        \n",
    "        flatten_1 = Flatten()(average_pool_1)\n",
    "        drop_1 = Dropout(0.2)(flatten_1)\n",
    "        dense_1 = Dense(2000, activation = 'relu')(drop_1)\n",
    "        \n",
    "        dense_2 = Dense(num_classes, activation = 'sigmoid')(dense_1)\n",
    "        \n",
    "        output = Lambda(lambda x: x/K.sum(x), name = 'normalization')(dense_2)\n",
    "\n",
    "        no_of_inputs = len(sublayers)\n",
    "\n",
    "        super(CustomCNNMultiple, self).__init__(inputs = input_1,\n",
    "                                                outputs = output,\n",
    "                                                inputshape = inputshape,\n",
    "                                                num_classes = num_classes,\n",
    "                                                no_of_inputs = no_of_inputs,\n",
    "                                                name = 'Custom_CNN_multiple')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "76OKygMa9Xr9"
   },
   "source": [
    "### Build the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Af3wbjEW9Xr-"
   },
   "outputs": [],
   "source": [
    "clf.model = CustomCNNMultiple(clf.input_shape, clf.num_classes)\n",
    "\n",
    "# Alternative: Build model from available models\n",
    "#clf.model = models.CustomCNNMultiple(clf.input_shape, clf.num_classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "I2SpBC-R9XsA"
   },
   "source": [
    "### Compile and summarize the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "vKQZDayn9XsB"
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.optimizers import Adam\n",
    "learning_rate = 1e-05\n",
    "optimizer = Adam(learning_rate = learning_rate) \n",
    "\n",
    "\n",
    "def custom_loss(y_true, y_pred):\n",
    "    \"\"\"\n",
    "    Custom loss for linear combination of XPS spectra.\n",
    "    \"\"\"\n",
    "    squared_difference = tf.square(y_true - y_pred)\n",
    "    return tf.reduce_mean(squared_difference, axis=-1)  # Note the `axis=-1`\n",
    "\n",
    "# Compile model with build-in loss function\n",
    "clf.model.compile(loss = custom_loss, optimizer = 'adam', )\n",
    "\n",
    "\n",
    "# Plot summary and save model plot.\n",
    "clf.summary()\n",
    "clf.save_and_print_model_image()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "GDOgVS_bLwGC"
   },
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "abV_fFCb5fiZ"
   },
   "outputs": [],
   "source": [
    "epochs = 150\n",
    "batch_size = 32\n",
    "\n",
    "hist = clf.train(checkpoint = True,\n",
    "                 early_stopping = False,\n",
    "                 tb_log = True, \n",
    "                 csv_log = True,\n",
    "                 epochs = epochs, \n",
    "                 batch_size = batch_size,\n",
    "                 verbose = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "J9uYqsMlLwGJ"
   },
   "source": [
    "### Graphs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Ffr2nfZy5nYi"
   },
   "outputs": [],
   "source": [
    "dir_name = clf.time + '_' + clf.data_name\n",
    "graph = clfutils.TrainingGraphs(clf.history, dir_name)\n",
    "graph.plot_loss()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "jnAnvSXLLwGQ"
   },
   "source": [
    "### Evaluation on test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "4g_QmUYG5fuT"
   },
   "outputs": [],
   "source": [
    "test_loss = clf.evaluate()\n",
    "print('Test loss: ' + str(np.round(test_loss, decimals=3)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "2uCoVCI-LwGY"
   },
   "source": [
    "###  Prediction on test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ezklX5YY5fyr"
   },
   "outputs": [],
   "source": [
    "pred_train, pred_test = clf.predict()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "nWbogghiLwGl"
   },
   "source": [
    "### Show some predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "T5DGB_OGLwGm"
   },
   "source": [
    "#### 5 random training samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "keDKIJriLwGn"
   },
   "outputs": [],
   "source": [
    "clf.plot_random(no_of_spectra = 6, dataset = 'train', with_prediction = True)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "-PHAS9XILwGr"
   },
   "source": [
    "#### 5 random test samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "HM3ZZf-qLwGs"
   },
   "outputs": [],
   "source": [
    "clf.plot_random(no_of_spectra = 6, dataset = 'test', with_prediction = True)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "KwrgvaLpLwG3"
   },
   "source": [
    "### Saving model and data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "2HBdnZSq5f2D"
   },
   "outputs": [],
   "source": [
    "clf.save_model()\n",
    "clf.save_hyperparams()\n",
    "clf.shelve_results(full = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "c6B2wITlLwG_"
   },
   "source": [
    "### Report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "-rPXD0ki5pOp"
   },
   "outputs": [],
   "source": [
    "dir_name = clf.time + '_' + clf.data_name\n",
    "rep = clfutils.Report(dir_name)  \n",
    "rep.write()   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Pk-dt26OLwHE"
   },
   "source": [
    "### Save output of notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "mkSdyElDLwHF"
   },
   "outputs": [],
   "source": [
    "from IPython.display import Javascript, display\n",
    "from nbconvert import HTMLExporter\n",
    "\n",
    "def save_notebook():\n",
    "    display(Javascript(\"IPython.notebook.save_notebook()\"),\n",
    "            include=['application/javascript'])\n",
    "\n",
    "def output_HTML(read_file, output_file):\n",
    "    import codecs\n",
    "    import nbformat\n",
    "    exporter = HTMLExporter()\n",
    "    # read_file is '.ipynb', output_file is '.html'\n",
    "    output_notebook = nbformat.read(read_file, as_version=4)\n",
    "    output, resources = exporter.from_notebook_node(output_notebook)\n",
    "    codecs.open(output_file, 'w', encoding='utf-8').write(output)\n",
    "\n",
    "import time\n",
    "import os\n",
    "\n",
    "save_notebook()\n",
    "time.sleep(10)\n",
    "current_file = '/content/drive/My Drive/app/xpsdeeplearning/train_colab_multiple.ipynb'\n",
    "output_file = os.path.join(clf.log_dir,'train_colab_multiple_out.html')\n",
    "output_HTML(current_file, output_file)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "train_colab_multiple.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
